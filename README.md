# TerrainMesh
Mesh Reconstruction for Terrain Mapping (ICRA 2021)

## Dataset link
Please download the dataset through the [Google Drive link](https://drive.google.com/drive/folders/1upXfSOmUZNv_s7lcL4Jazo-8UNiVENmh?usp=sharing).

## Structure
There are 14 sequences in the train, 2 sequences in the val and 4 sequences in the test. Each sequence contains 200 images. For each sequence there are 7 folders.
```
train
    train/002_36
        train/002_36/Cams
        train/002_36/Depths
        train/002_36/Images
        train/002_36/Meshes
        train/002_36/Pcds
        train/002_36/Pcds_1000
        train/002_36/Pcds_1000_gt
    ...
val
    ...
test
    ...
```


## Folders

* **Cams**  
Stores the camera intrinsics and extrinsics. All the images share the same intrinsics. The intrinsic parameters are [f cx cy width height], f=fx=fy. The extrinsic is a 4x4 matrix of SE(3) with identity rotation. One example is
```
intrinsic
2560.000000 256.000000 256.000000 512 512

extrinsic
1.000000 0.000000 0.000000 -1475.000000 
0.000000 1.000000 0.000000 -950.000000 
0.000000 0.000000 1.000000 1270.000000 
0.000000 0.000000 0.000000 1.000000 
```


* **Depths**  
Stores the groundtruth depth images. The depth image is stored in 16-bit and the real depth value can be derived by dividing 64. The expected depth should be around 500. Here is one example of reading a depth image and get the real depth values by [OpenCV-Python](https://github.com/opencv/opencv-python).
```
import cv2 
depth = cv2.imread("Depths/0000.png",-1) #-1 is equivalent to cv2.IMREAD_UNCHANGED. 
depth = depth/64.
print(depth)
(Expecting a 2D array with value around 500.)
```

* **Images**  
Stores the RGB images.

* **Meshes**  
Stores the (pseudo-)groundtruth mesh for the single view generated by optimizing a dense mesh using dense depth map. See Sec. IV of [1] for details. 

* **Pcds**  
Stores the noisy sparse point clouds generated using [OpenSfM](https://www.opensfm.org/). These are noisy point clouds without downsampled. For downsampled point clouds, see Pcds_1000 and Pcd_1000_gt. See Sec. VI A of [1] for details.  
The "xxxx.ply" is the 3D point cloud format. The "xxxx.png" is the 2D sparse depth map format. Notice the 2D sparse depth map follows the same format of the groundtruth depth images, i.e., is stored in 16-bit and the real depth value can be derived by dividing 64.

* **Pcds_1000** 
Stores the noisy sparse point clouds sampled from **Pcds**. We sampled 1000 points but after projecting to the 2D image plane the number might be slightly smaller. 

* **Pcds_1000_gt**
Stores the noise-free sparse point clouds sampled from Pcds. We use the same sample patterns in **Pcds_1000** but read the groundtruth depth value from **Depths**. 


### Notice
Notice the 2D sparse depth maps in **Pcds**, **Pcds_1000**, **Pcds_1000_gt** follow the same format of the groundtruth depth images in **Depths**, i.e., is stored in 16-bit and the real depth value can be derived by dividing 64.


## Ref
The dataset is developed from [WHU MVS/Stereo Dataset](http://gpcv.whu.edu.cn/data/WHU_MVS_Stereo_dataset.html). If you find this helpfut to you project, please consider cite  
[1] Q. Feng and N. Atanasov, “Mesh Reconstruction from Aerial Images for Outdoor Terrain Mapping Using Joint 2D-3D Learning,” in IEEE International Conference on Robotics and Automation (ICRA), 2021.  
[2] J. Liu and S. Ji, “A Novel Recurrent Encoder-Decoder Structure for Large-Scale Multi-View Stereo Reconstruction From an Open AerialDataset,” in IEEE/CVF Conference on Computer Vision and PatternRecognition (CVPR), 2020, pp. 6049–6058.
